# -*- coding: utf-8 -*-
"""GetEventsData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r0pRvcvsEGVI2lDev1fXaEGM-NZnkkRh
"""

import requests
import json
import pandas as pd
import time
import calendar
import numpy as np

api_key = 'qF1IyhSFEMjvqQPMGKtulGpTyj6DEpr7'
base_url = "https://app.ticketmaster.com/discovery/v2/events.json"

def get_events(params):
    events_list = [] # Step 2: Initialize an empty list

    try:
        response = requests.get(base_url, params=params)
        response.raise_for_status()
        data = response.json()

        if '_embedded' in data and data['_embedded']['events']:
            events = data['_embedded']['events']
            print(f"Found {len(events)} events in Toronto for 2025. Processing...")

            for event in events:
                # --- Extract all the data for one event ---
                event_name = event['name']
                event_date = event['dates']['start'].get('localDate', 'Date not available')

                venue_info = event.get('_embedded', {}).get('venues', [{}])[0]
                venue_name = venue_info.get('name', 'Venue not available')
                event_address = venue_info.get('address', {}).get('line1', 'Address not available')
                location_info = venue_info.get('location', {})
                latitude = location_info.get('latitude', 'N/A')
                longitude = location_info.get('longitude', 'N/A')

                classifications_list = event.get('classifications', [])
                segment_name = 'N/A'
                genre_name = 'N/A'
                subgenre_name = 'N/A'

                if classifications_list:
                    primary_classification = classifications_list[0]
                    segment_name = primary_classification.get('segment', {}).get('name', 'N/A')
                    genre_name = primary_classification.get('genre', {}).get('name', 'N/N')
                    subgenre_name = primary_classification.get('subGenre', {}).get('name', 'N/A')

                # Step 3: Create a dictionary for the current event
                event_data = {
                    'Event Name': event_name,
                    'Date': event_date,
                    'Venue': venue_name,
                    'Address': event_address,
                    'Latitude': latitude,
                    'Longitude': longitude,
                    'Segment': segment_name,
                    'Genre': genre_name,
                    'SubGenre': subgenre_name
                }

                # Step 4: Append the dictionary to the list
                events_list.append(event_data)

        else:
            print("No events found in Toronto for 2025 with the given criteria.")

    except requests.exceptions.RequestException as e:
        print(f"An error occurred: {e}")
    except KeyError:
        print("Could not parse the event data. The response format may have changed.")

    return events_list # Return the list of events

MAX_PAGE_LIMIT = 5 # Constant for the API's page limit (0-indexed)

def get_all_events(params, base_url):
    """Fetches all events for a given set of parameters, handling pagination."""
    events_list = []
    current_page = 0
    total_pages = 1

    while current_page < total_pages and current_page < MAX_PAGE_LIMIT:
        try:
            params['page'] = current_page
            response = requests.get(base_url, params=params)
            response.raise_for_status()
            data = response.json()

            if current_page == 0 and 'page' in data:
                total_pages = data['page'].get('totalPages', 1)
                print(f"API reports {total_pages} total pages. Will fetch up to page {MAX_PAGE_LIMIT}.")

            if '_embedded' in data and 'events' in data['_embedded']:
                events = data['_embedded']['events']
                print(f"  Processing page {current_page + 1}/{min(total_pages, MAX_PAGE_LIMIT)}... Found {len(events)} events.")
                for event in events:
                    # Data extraction logic
                    event_data = {
                        'Event Name': event.get('name'),
                        'Date': event.get('dates', {}).get('start', {}).get('localDate', 'N/A'),
                        'Venue': event.get('_embedded', {}).get('venues', [{}])[0].get('name', 'N/A'),
                        'Address': event.get('_embedded', {}).get('venues', [{}])[0].get('address', {}).get('line1', 'N/A'),
                        'Latitude': event.get('_embedded', {}).get('venues', [{}])[0].get('location', {}).get('latitude', 'N/A'),
                        'Longitude': event.get('_embedded', {}).get('venues', [{}])[0].get('location', {}).get('longitude', 'N/A'),
                        'Segment': event.get('classifications', [{}])[0].get('segment', {}).get('name', 'N/A'),
                        'Genre': event.get('classifications', [{}])[0].get('genre', {}).get('name', 'N/A'),
                        'SubGenre': event.get('classifications', [{}])[0].get('subGenre', {}).get('name', 'N/A')
                    }
                    events_list.append(event_data)
            else:
                break
            current_page += 1
            time.sleep(0.2)
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 400:
                print(f"  Caught a 400 Client Error on page {current_page}. Likely hit API result limit. Stopping fetch for this period.")
                break
            else:
                print(f"  An HTTP error occurred: {e}")
                break
        except requests.exceptions.RequestException as e:
            print(f"  A network error occurred: {e}")
            break

    return events_list

params = {
    'apikey': api_key,
    'city': 'Toronto',
    'startDateTime': '2025-01-01T00:00:00Z',
    'endDateTime': '2025-12-31T23:59:59Z',
    'size': 200
}
# events_list = get_all_events(params)

# if events_list:
#     events_df = pd.DataFrame(events_list)
YEAR = 2025

all_year_events = [] # A master list to hold all events from all months

# Loop through each month of the year
for month in range(1, 13):
    # Determine the last day of the current month
    _, num_days = calendar.monthrange(YEAR, month)

    # Format the start and end datetime strings for the API query
    start_date = f"{YEAR}-{month:02d}-01T00:00:00Z"
    end_date = f"{YEAR}-{month:02d}-{num_days:02d}T23:59:59Z"

    print(f"\n--- Fetching events for {calendar.month_name[month]} {YEAR} ---")

    # Set parameters for the current month
    monthly_params = {
        'apikey': api_key,
        'city': 'Toronto',
        'startDateTime': start_date,
        'endDateTime': end_date,
        'size': 200
    }

    # Call the function and get events for this month
    monthly_events = get_all_events(monthly_params, base_url)

    # Add the results from this month to our master list
    if monthly_events:
        all_year_events.extend(monthly_events)
        print(f"--- Found {len(monthly_events)} events for {calendar.month_name[month]} ---")

# --- Final DataFrame Creation ---
print(f"\nFinished fetching all months. Total events for the year: {len(all_year_events)}")

if all_year_events:
    df = pd.DataFrame(all_year_events)
    print("\nSuccessfully created DataFrame with all events for the year.")
    print("DataFrame Info:")
    df.info()
    print("\nFirst 5 rows of the DataFrame:")
    print(df.head())


df.to_csv('Data/toronto_events_2025.csv', index=False)
print("DataFrame saved to toronto_events_2025.csv")

"""Scoring Events

"""

def create_event_scores(input_filename='toronto_events_2025.csv', output_filename='toronto_events_with_scores.csv'):
    """
    Loads event data, calculates a heuristic event score with special keyword handling,
    and saves the results.
    """
    try:
        df = pd.read_csv(input_filename)
        print("Successfully loaded the dataset.")
    except FileNotFoundError:
        print(f"Error: '{input_filename}' not found. Please make sure the file is in the same directory.")
        return

    # --- 1. Define Scoring Dictionaries ---

    # NEW: Dictionary for major city-wide events and festivals
    # Keywords are checked against the 'Event Name'. The score here will override all others.
    special_event_scores = {
        'film festival': 12.0,
        'tiff': 12.0,
        'pride': 11.5,
        'caribbean carnival': 11.0,
        'caribana': 11.0,
        'indy': 10.5,
        'marathon': 10.0,
        'fan expo': 9.5,
        'nuit blanche': 9.0,
        'luminato': 9.0,
        'cne': 8.5,
        'canadian national exhibition': 8.5
    }

    # (The rest of the scoring dictionaries remain the same)
    segment_scores = {
        'Sports': 9, 'Music': 8, 'Arts & Theatre': 6,
        'Miscellaneous': 3, 'Undefined': 2, 'N/A': 2
    }
    genre_scores = {
        'Hockey': 9, 'Basketball': 9, 'Baseball': 8, 'R&B': 7,
        'Rock': 7, 'Pop': 7, 'Theatre': 6, 'Soccer': 7,
        'Comedy': 5, 'Undefined': 2, 'N/A': 2
    }
    subgenre_scores = {
        'NHL': 10, 'NBA': 10, 'MLB': 9, 'Musical': 7, 'R&B': 7,
        'Rock': 7, 'Pop': 7, 'Alternative': 6, 'Undefined': 2, 'N/A': 2
    }
    venue_multipliers = {
        'Rogers Centre': 1.5, 'Scotiabank Arena': 1.2, 'Budweiser Stage': 1.2,
        'Coca-Cola Coliseum': 1.0, 'History': 1.0, 'Massey Hall': 1.0,
        'The Danforth Music Hall': 1.0, 'Meridian Hall': 1.0, 'Ed Mirvish Theatre': 1.0,
        'Comedy Bar - Danforth': 0.8, 'NOVENUE': 0.5
    }
    default_venue_multiplier = 0.9

    # --- 2. UPDATED Scoring Function ---

    def calculate_event_score(row):
        # First, check for special event keywords in the event name (case-insensitive)
        event_name_lower = str(row['Event Name']).lower()
        for keyword, score in special_event_scores.items():
            if keyword in event_name_lower:
                return score # Override with the special score and stop

        # If no special keyword is found, proceed with the original logic
        segment = row.get('Segment') if pd.notna(row.get('Segment')) else 'N/A'
        genre = row.get('Genre') if pd.notna(row.get('Genre')) else 'N/A'
        subgenre = row.get('SubGenre') if pd.notna(row.get('SubGenre')) else 'N/A'

        s_score = segment_scores.get(segment, 2)
        g_score = genre_scores.get(genre, 2)
        sg_score = subgenre_scores.get(subgenre, 2)

        base_score = (s_score + g_score + sg_score) / 3
        multiplier = venue_multipliers.get(row['Venue'], default_venue_multiplier)
        event_score = base_score * multiplier
        return round(event_score, 2)

    # --- 3. Apply the function and save the results ---
    df['event_score'] = df.apply(calculate_event_score, axis=1)
    df_sorted = df.sort_values(by='event_score', ascending=False)
    df_sorted.to_csv(output_filename, index=False)

    print(f"\nSuccessfully created '{output_filename}' with UPGRADED event scores.")
    print("\nTop 10 Events by Score (New Logic):")
    print(df_sorted[['Event Name', 'Venue', 'event_score']].head(10))

create_event_scores()

"""High Score (9+): Major stadium/arena events (NHL, MLB, A-list concerts) that are primary drivers of city-wide hotel demand.

Medium Score (5-8): Significant theatre productions or concerts at large halls that create a noticeable, regional spike in demand.

Low Score (<5): Local events at smaller venues (clubs, bars) with minimal impact on the overall hotel market.
"""